{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a simple RAG Application with CrewAI\n",
    "---\n",
    "\n",
    "CrewAI is a cutting-edge framework for orchestrating autonomous AI agents. CrewAI enables you to create AI teams where each agent has specific roles, tools, and goals, working together to accomplish complex tasks.\n",
    "\n",
    "**CrewAI has the following main components:**\n",
    "\n",
    "1. `Crew`: This is the top level management system that manages various AI teams, breaks down simple tasks and delegates those tasks, ensures collaboration between the agents and ensures task completion.\n",
    "\n",
    "1. `AI Agents`: These are specialized entities (agents), could be a writer, researcher, etc. These agents have the power to make autonomous decisions and perform certain tasks.\n",
    "\n",
    "1. `Process`: This is the workflow that defines the collaboration patterns between the sub agents, controls the task assignments, interactions and task execution.\n",
    "\n",
    "1. `Tasks`: These are well-defined micro-level tasks that are supposed to be executed by the AI agent to produce some level of actionable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install crew ai. For installation steps, follow the instructions here: https://docs.crewai.com/installation\n",
    "!pip install 'crewai[tools]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the crew ai installation\n",
    "!pip freeze | grep crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add docling\n",
    "!uv add crewai\n",
    "!uv add langchain\n",
    "!uv add requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import typing\n",
    "import logging\n",
    "import requests\n",
    "from crewai import LLM\n",
    "from crewai import Task\n",
    "from crewai import Agent\n",
    "from crewai_tools import SerperDevTool\n",
    "from typing import List, Dict, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "\n",
    "logger.info(f\"current region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variables that will be used across this notebook\n",
    "BEDROCK_NOVA_LITE_MODEL: str = 'us.amazon.nova-lite-v1:0'\n",
    "BEDROCK_CLAUDE_3_5_SONNET_V1_MODEL: str = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "BEDROCK_CLAUDE_3_HAIKU: str = \"us.anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "BEDROCK_LLAMA3_1_70B_MODEL: str = \"us.meta.llama3-1-70b-instruct-v1:0\"\n",
    "TITAN_TEXT_EMBED_V2: str = 'amazon.titan-embed-text-v2:0'\n",
    "DATA_DIR: str = \"data\"\n",
    "AWS_SERVICES_PDF_URL: str = \"https://docs.aws.amazon.com/pdfs/whitepapers/latest/aws-overview/aws-overview.pdf\"\n",
    "PDF_FILE_NAME_LOCAL: str = \"aws_overview.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the knowledge for the agent\n",
    "---\n",
    "\n",
    "In this portion of the notebook, we will store the AWS service PDF file as a `string_knowledge_source`. CrewAI supports text (`PDF`, `raw strings`, `text files`) and structured data (`CSV`, `JSON`, `Excel`) files.\n",
    "\n",
    "In this example, we will create a custom knowledge base to store information from the AWS service PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an embedder\n",
    "embedder = {\n",
    "    \"provider\": \"bedrock\",\n",
    "    \"config\": {\n",
    "        \"model\": TITAN_TEXT_EMBED_V2\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "try:\n",
    "    response = requests.get(AWS_SERVICES_PDF_URL)\n",
    "    response.raise_for_status()\n",
    "    # Save directly to root directory\n",
    "    with open(PDF_FILE_NAME_LOCAL, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"PDF successfully downloaded to root directory as {PDF_FILE_NAME_LOCAL}\")\n",
    "\n",
    "    # Create 'knowledge' directory if it doesn't exist\n",
    "    if not os.path.exists('knowledge'):\n",
    "        os.makedirs('knowledge')\n",
    "    \n",
    "    # Copy the PDF to knowledge directory\n",
    "    shutil.copy(PDF_FILE_NAME_LOCAL, os.path.join('knowledge', PDF_FILE_NAME_LOCAL))\n",
    "    print(f\"PDF copied to knowledge directory\")\n",
    "    pdf_source = PDFKnowledgeSource(file_paths=[PDF_FILE_NAME_LOCAL], embedder=embedder)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while downloading the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CrewAI Agent\n",
    "---\n",
    "\n",
    "In this portion of the notebook, we will create an Agent using the agent class. There are various ways to create an agent, using a [YAML file](https://docs.crewai.com/concepts/agents) or directly through the [code](https://docs.crewai.com/concepts/agents). For the purpose of this RAG example, we will be creating an agent through simple python code using an Agent class.\n",
    "\n",
    "In the example below, we will create a simple RAG agent that is an AWS service provider and a code generation agent that will generate code based on user requests. It has access to large amounts of data and will be able to answer questions about that data and perform other simple tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic configuration\n",
    "llm = LLM(\n",
    "    model=f\"bedrock/{BEDROCK_CLAUDE_3_HAIKU}\", \n",
    "    temperature=0.1,        # Higher for more creative outputs\n",
    "    timeout=120,           # Seconds to wait for response\n",
    "    max_tokens=256,       # Maximum length of response\n",
    "    top_p=0.9,            # Nucleus sampling parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will create an agent that is an AWS solutions architect and assists users with questions about\n",
    "# their journey on AWS cloud\n",
    "\n",
    "# Create an agent with all available parameters\n",
    "aws_agent = Agent(\n",
    "    role=\"AWS Solutions Architect. All requests are routed to this agent about AWS\",\n",
    "    goal=\"Analyze the customer question and best assist them by answering and providing accurate answers about the AWS cloud. All requests are routed to this agent about AWS\",\n",
    "    backstory=\"With over 10 years of experience solutions architecture and AWS cloud, \"\n",
    "              \"you excel at supporting customers in their journeys on the cloud. You are highly technical and can,\"\n",
    "              \"answer customer questions with ease. If there is a question you don't know the answer to, you never second guess, \"\n",
    "              \"you always answer truthfully and accurately.\",\n",
    "    llm=llm,  \n",
    "    function_calling_llm=None,  # Optional: Separate LLM for tool calling\n",
    "    memory=True,  # Default: True\n",
    "    verbose=False,  # Default: False\n",
    "    allow_delegation=False,  # Default: False\n",
    "    max_iter=20,  # Default: 20 iterations\n",
    "    max_rpm=None,  # Optional: Rate limit for API calls\n",
    "    max_execution_time=None,  # Optional: Maximum execution time in seconds\n",
    "    max_retry_limit=2,  # Default: 2 retries on error\n",
    "    respect_context_window=True,  # Default: True\n",
    "    use_system_prompt=True,  # Default: True\n",
    "    # we will pass in the content source as a knowledge base for the aws agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will create a code generation agent that will generate code based on the user's input. \n",
    "dev_agent = Agent(\n",
    "    role=\"Senior Python Developer. All coding related questions are routed to this agent\",\n",
    "    goal=\"Write and debug Python code\",\n",
    "    backstory=\"Expert Python developer with 10 years of experience\",\n",
    "    llm=llm,\n",
    "    allow_code_execution=True,\n",
    "    code_execution_mode=\"safe\",  # Uses Docker for safety\n",
    "    max_execution_time=300,  # 5-minute timeout\n",
    "    max_retry_limit=3  # More retries for complex code tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agentic tasks\n",
    "---\n",
    "\n",
    "Tasks provide all necessary details for execution, such as a description, the agent responsible, required tools, and more, facilitating a wide range of action complexities. In this portion of the notebook, we will create tasks for each agent that it will be able to perform. Tasks within CrewAI can be collaborative, requiring multiple agents to work together. This is managed through the task properties and orchestrated by the Crewâ€™s process, enhancing teamwork and efficiency.\n",
    "\n",
    "Tasks can either be executed `sequentially` (in the case of which an agent needs to perform with conditions) or `hierarchical` (tasks are assigned to the agent based on the role and expertise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_agent_task = Task(\n",
    "    description=\"\"\"\n",
    "        Conduct findings based on the user question about AWS. Fetch\n",
    "        all the relevant information from data provided and provide a \n",
    "        comprehensive report.\n",
    "    \"\"\",\n",
    "    expected_output=\"\"\"\n",
    "        A detailed report based on the user question about AWS. \n",
    "        The report should include all the relevant information fetched from data provided.\n",
    "    \"\"\",\n",
    "    agent=aws_agent\n",
    ")\n",
    "\n",
    "development_task = Task(\n",
    "    description=\"\"\"\n",
    "        Make sure to generate code for what the user is asking for. This\n",
    "        code is in python and it is simple and executable. Only generate the code if the user\n",
    "        is asking for a coding problem.\n",
    "    \"\"\",\n",
    "    expected_output=\"\"\"\n",
    "        A  python code that can be executed directly. The code should not\n",
    "        contain any filler words and should only be the code that can be\n",
    "        executed directly.\n",
    "    \"\"\",\n",
    "    agent=dev_agent,\n",
    "    output_file=f\"{DATA_DIR}/code.py\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Defined the AWS task: {aws_agent_task}\")\n",
    "print(f\"Defined the development task: {development_task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Process, Task\n",
    "\n",
    "# define the manager model that is used to route request to the best agent\n",
    "manager_llm = LLM(model=f\"bedrock/{BEDROCK_CLAUDE_3_5_SONNET_V1_MODEL}\", \n",
    "                    temperature=0.1,        # Higher for more creative outputs\n",
    "                    timeout=120,           # Seconds to wait for response\n",
    "                    max_tokens=256,       # Maximum length of response\n",
    "                    top_p=0.9,            # Nucleus sampling parameter\n",
    "                )\n",
    "\n",
    "embedder_config = {\n",
    "    \"provider\": \"bedrock\",\n",
    "    \"config\": {\n",
    "        \"model\": TITAN_TEXT_EMBED_V2,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create and run the crew\n",
    "crew = Crew(\n",
    "    manager_llm=manager_llm,\n",
    "    agents=[aws_agent, dev_agent],\n",
    "    tasks=[aws_agent_task, development_task],\n",
    "    verbose=True,\n",
    "    process=Process.hierarchical, \n",
    "    # planning=True, # Assemble your crew with planning capabilities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "result = crew.kickoff(\n",
    "    inputs={\"user_question\": \"What are the main categories of AWS services?\"}\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
